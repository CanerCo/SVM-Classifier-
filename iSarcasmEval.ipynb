{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import preprocessor as p\n",
    "import functools\n",
    "import operator\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from emoji import *\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel, BertTokenizer, BertModel\n",
    "from gensim.models import KeyedVectors\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom packages\n",
    "\n",
    "import sys\n",
    "sys.path.append('./code')\n",
    "\n",
    "from data_preprocessing import *\n",
    "from tweets_embedding import *\n",
    "from frnn_owa_eval import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "\n",
    "irony_train = pd.read_csv('./data/train.En.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>rephrase</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>College is really difficult, expensive, tiring...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic  \\\n",
       "0  The only thing I got from college is a caffein...          1   \n",
       "\n",
       "                                            rephrase  sarcasm  irony  satire  \\\n",
       "0  College is really difficult, expensive, tiring...      0.0    1.0     0.0   \n",
       "\n",
       "   understatement  overstatement  rhetorical_question  \n",
       "0             0.0            0.0                  0.0  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loon on the dataset\n",
    "\n",
    "irony_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The only thing I got from college is a caffeine addiction                                                                                                                                                                                     \n",
       "1    I love it when professors draw a big question mark next to my answer on an exam because I‚Äôm always like yeah I don‚Äôt either ¬Ø\\_(„ÉÑ)_/¬Ø                                                                                                         \n",
       "2    Remember the hundred emails from companies when Covid started getting real? I‚Äôve gotten three in regards to support for protests. And only @SavageXFenty shared helpful links and actually said black lives matter... we love capitalism ü•∞üôåüèº  \n",
       "3    Today my pop-pop told me I was not ‚Äúforced‚Äù to go to college üôÉ okay sure sureeee                                                                                                                                                              \n",
       "4    @VolphanCarol @littlewhitty @mysticalmanatee I did too, and I also reported Cancun Cruz not worrying about the heartbeats of his constituents without electricity or heat when he fled to Mexico.                                             \n",
       "5    @jimrossignol I choose to interpret it as \"XD\": the universal emoticon for laughing at those poor, poor folks in Ubisoft's marketing department who have to deal with that branding until the servers quietly shut down 8 months after launch.\n",
       "6    Why would Alexa's recipe for Yorkshire pudding be a bhaji yorkshire pudding ?? @bbcgoodfood                                                                                                                                                   \n",
       "7    someone hit me w a horse tranquilizer istg ive been in a pool of sweat for 6 hours and i havent slept im so tired but i love my friend so much and oh my fucking god i cant rn                                                                \n",
       "8    Loving season 4 of trump does America. Funniest season yet #DonaldTrump #Trump #MAGA #MAGA2020                                                                                                                                                \n",
       "9    Holly Arnold ??? Who #ImACeleb  #MBE nope not sure oh hang on you mean MBE yes that‚Äôs her !!!                                                                                                                                                 \n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look on tweets\n",
    "\n",
    "irony_train['tweet'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train instances:  3468\n",
      "Size of the irony class:  867\n",
      "Size of the non-irony class:  2601\n"
     ]
    }
   ],
   "source": [
    "# Datasets charachteristics\n",
    "\n",
    "print('Number of train instances: ', len(irony_train)) \n",
    "print('Size of the sarcastic class: ', len(irony_train[irony_train.sarcastic == 1])) \n",
    "print('Size of the non-sarcastic class: ', len(irony_train[irony_train.sarcastic == 0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Subtask A we need only binary classes presented at \"sarcastic\" column\n",
    "\n",
    "irony_train_select = irony_train[['tweet', 'sarcastic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function on tweets\n",
    "\n",
    "irony_train_select['cleaned_tweet'] = irony_train_select['tweet'].apply(lambda x: clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete stopwords\n",
    "\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "\n",
    "irony_train_select['cleaned_tweet_wt_stopwords'] = irony_train_select['cleaned_tweet'].apply(lambda x:\n",
    "                                         ' '.join([i for i in x.split(' ') if i not in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply text embedding techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**roBERTa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the pre-downloaded irony-based Twitter-roBERTa model \n",
    "\n",
    "model_roberta_path = r\"./model/twitter-roberta-base-irony\"\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained(model_roberta)\n",
    "model_roberta = TFAutoModel.from_pretrained(model_roberta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply roBERTa-based\n",
    "\n",
    "irony_train_select['Vector_roBERTa'] = irony_train_select['tweet'].apply(lambda x: \n",
    "                                                     get_vector_roberta(x, tokenizer_roberta, model))\n",
    "\n",
    "irony_train_select['Vector_roBERTa_cleaned'] = irony_train_select['cleaned_tweet'].apply(lambda x: \n",
    "                                                     get_vector_roberta(x, tokenizer_roberta, model))\n",
    "irony_train_select['Vector_roBERTa_wt_stopwords'] = \n",
    "                    irony_train_select['cleaned_tweet_wt_stopwords'].apply(lambda x: \n",
    "                                                   get_vector_roberta(x, tokenizer_roberta, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the pre-downloaded Word2Vec model \n",
    "\n",
    "w2v_path = './model/GoogleNews-vectors-negative300.bin'\n",
    "w2v_model = KeyedVectors.load_word2vec_format(w2v_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Word2Vec \n",
    "\n",
    "irony_train_select[\"Vector_w2v\"] = irony_train_select['tweet'].apply(lambda x: \n",
    "                                                                     get_vector_w2v(x, w2v_model))\n",
    "irony_train_select[\"Vector_w2v_cleaned\"] = irony_train_select['cleaned_tweet'].apply(lambda x: \n",
    "                                                                     get_vector_w2v(x, w2v_model))\n",
    "irony_train_select[\"Vector_w2v_wt_stopwords\"] = \n",
    "        irony_train_select['cleaned_tweet_wt_stopwords'].apply(lambda x: get_vector_w2v(x, w2v_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Universal Sentence Encoder  (USE)\n",
    "\n",
    "model_use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply USE\n",
    "\n",
    "irony_train_select['Vector_use'] = irony_train_select['tweet'].apply(lambda x: \n",
    "                                                                     get_vector_use(x, model_use))\n",
    "irony_train_select['Vector_use_cleaned'] = irony_train_select['cleaned_tweet'].apply(lambda x: \n",
    "                                                                         get_vector_use(x, model_use))\n",
    "irony_train_select['Vector_use_wt_stopwords'] = \n",
    "        irony_train_select['cleaned_tweet_wt_stopwords'].apply(lambda x: get_vector_use(x, model_use))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Sentence-SBERT\n",
    "\n",
    "model_sbert = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SBERT\n",
    "\n",
    "irony_train_select['Vector_sbert'] = irony_train_select['tweet'].apply(lambda x: \n",
    "                                                                   get_vector_sbert(x, model_sbert))\n",
    "irony_train_select['Vector_sbert_cleaned'] = irony_train_select['cleaned_tweet'].apply(lambda x: \n",
    "                                                                   get_vector_sbert(x, model_sbert))\n",
    "irony_train_select['Vector_sbert_wt_stopwords'] = \n",
    "    irony_train_select['cleaned_tweet_wt_stopwords'].apply(lambda x: get_vector_sbert(x, model_sbert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload BERT\n",
    "\n",
    "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply BERT \n",
    "\n",
    "irony_train_select['Vector_bert'] = irony_train_select['tweet'].apply(lambda x: \n",
    "                                                      get_vector_bert(x, tokenizer_bert, model_bert))\n",
    "irony_train_select['Vector_bert_cleaned'] = irony_train_select['cleaned_tweet'].apply(lambda x: \n",
    "                                                      get_vector_bert(x, tokenizer_bert, model_bert))\n",
    "irony_train_select['Vector_bert_wt_stopwords'] = \n",
    "                    irony_train_select['cleaned_tweet_wt_stopwords'].apply(lambda x: \n",
    "                                                    get_vector_bert(x, tokenizer_bert, model_bert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DeepMoji**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DeepMoji\n",
    "\n",
    "irony_train_select['Vector_deepmoji'] = get_vectors_deepmoji(irony_train_select, 'tweet')\n",
    "irony_train_select['Vector_deepmoji_cleaned'] = get_vectors_deepmoji(irony_train_select, 'cleaned_tweet')\n",
    "irony_train_select['Vector_deepmoji_wt_stopwords'] = get_vectors_deepmoji(irony_train_select, 'cleaned_tweet_wt_stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply FRNN-OWA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the single embedding methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use 5-fold cross-validation\n",
    "\n",
    "K_fold = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cleaned cells' outputs to reduce size of the Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**roBERTa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tweets\n",
    "\n",
    "f1_list = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, ['Vector_roBERTa'], \n",
    "                                                    'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets\n",
    "\n",
    "f1_list_cleaned = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                        ['Vector_roBERTa_cleaned'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_cleaned.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets without stopwords\n",
    "\n",
    "f1_list_wt_sw = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                    ['Vector_roBERTa_wt_stopwords'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_wt_sw.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.04680521585228239, pvalue=0.9631838653423619)\n",
      "Ttest_indResult(statistic=20.120009270873474, pvalue=8.686849539224575e-14)\n",
      "Ttest_indResult(statistic=20.401014807526536, pvalue=6.83542870303569e-14)\n"
     ]
    }
   ],
   "source": [
    "# Perform t-test to compare results\n",
    "# If 0.05 > p-value - arrays are different\n",
    "\n",
    "print(ttest_ind(f1_list, f1_list_cleaned))\n",
    "print(ttest_ind(f1_list_cleaned, f1_list_wt_sw))\n",
    "print(ttest_ind(f1_list, f1_list_wt_sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original or cleaned are the same. W/t stopwords are worse. \n",
    "\n",
    "The best: original tweets with k = 5, F1 = 0.3722"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tweets\n",
    "\n",
    "f1_list = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, ['Vector_bert'], \n",
    "                                                    'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets\n",
    "\n",
    "f1_list_cleaned = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                        ['Vector_bert_cleaned'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_cleaned.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets without stopwords\n",
    "\n",
    "f1_list_wt_sw = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                    ['Vector_bert_wt_stopwords'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_wt_sw.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=1.3844085091913392, pvalue=0.1801161254898383)\n",
      "Ttest_indResult(statistic=-4.556261390751205, pvalue=0.00015504283655645406)\n",
      "Ttest_indResult(statistic=-2.8396722723654793, pvalue=0.009534682719594437)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_ind(f1_list, f1_list_cleaned))\n",
    "print(ttest_ind(f1_list_cleaned, f1_list_wt_stopwords))\n",
    "print(ttest_ind(f1_list, f1_list_wt_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings for cleaned tweets without stopwords are better.\n",
    "\n",
    "The best: k = 5, F1 = 0.2351"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tweets\n",
    "\n",
    "f1_list = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, ['Vector_sbert'], \n",
    "                                                    'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets\n",
    "\n",
    "f1_list_cleaned = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                        ['Vector_sbert_cleaned'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_cleaned.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets without stopwords\n",
    "\n",
    "f1_list_wt_sw = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                    ['Vector_sbert_wt_stopwords'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_wt_sw.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.34927406544647377, pvalue=0.7302045757668506)\n",
      "Ttest_indResult(statistic=1.176300680212196, pvalue=0.25204665429833584)\n",
      "Ttest_indResult(statistic=1.3738676445845028, pvalue=0.18332052919051617)\n"
     ]
    }
   ],
   "source": [
    "#if 0.05 > p-value - arrays are different\n",
    "\n",
    "print(ttest_ind(f1_list, f1_list_cleaned))\n",
    "print(ttest_ind(f1_list_cleaned, f1_list_wt_stopwords))\n",
    "print(ttest_ind(f1_list, f1_list_wt_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They all are the same.\n",
    "\n",
    "The best is for original tweets, with k = 7, F1 = 0.1618"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tweets\n",
    "\n",
    "f1_list = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, ['Vector_use'], \n",
    "                                                    'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets\n",
    "\n",
    "f1_list_cleaned = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                        ['Vector_use_cleaned'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_cleaned.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets without stopwords\n",
    "\n",
    "f1_list_wt_sw = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                    ['Vector_use_wt_stopwords'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_wt_sw.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.8801216223546391, pvalue=0.38830675246570723)\n",
      "Ttest_indResult(statistic=1.706769695671753, pvalue=0.10194258358825793)\n",
      "Ttest_indResult(statistic=2.488074573613451, pvalue=0.02090406227474988)\n"
     ]
    }
   ],
   "source": [
    "#if 0.05 > p-value - arrays are different\n",
    "\n",
    "print(ttest_ind(f1_list, f1_list_cleaned))\n",
    "print(ttest_ind(f1_list_cleaned, f1_list_wt_stopwords))\n",
    "print(ttest_ind(f1_list, f1_list_wt_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best is embedding for the original tweets, k = 5, F1 = 0.2808"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DeepMoji**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tweets\n",
    "\n",
    "f1_list = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, ['Vector_deepmoji'], \n",
    "                                                    'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets\n",
    "\n",
    "f1_list_cleaned = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                        ['Vector_deepmoji_cleaned'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_cleaned.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets without stopwords\n",
    "\n",
    "f1_list_wt_sw = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                    ['Vector_deepmoji_wt_stopwords'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_wt_sw.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=1.5677094486136374, pvalue=0.13122100768593062)\n",
      "Ttest_indResult(statistic=2.327942293253145, pvalue=0.02950835720454593)\n",
      "Ttest_indResult(statistic=3.896138327258023, pvalue=0.0007767139224709184)\n"
     ]
    }
   ],
   "source": [
    "#if 0.05 > p-value - arrays are different\n",
    "\n",
    "print(ttest_ind(f1_list, f1_list_cleaned))\n",
    "print(ttest_ind(f1_list_cleaned, f1_list_wt_stopwords))\n",
    "print(ttest_ind(f1_list, f1_list_wt_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings for original and cleaned tweets are similar and better than for cleaned without stopwords\n",
    "\n",
    "The best is cleaned, k = 5, F1 = 0.3157"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tweets\n",
    "\n",
    "f1_list = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, ['Vector_w2v'], \n",
    "                                                    'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets\n",
    "\n",
    "f1_list_cleaned = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                        ['Vector_w2v_cleaned'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_cleaned.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned tweets without stopwords\n",
    "\n",
    "f1_list_wt_sw = []\n",
    "for k in [5, 7, 9, 11, 13, 15, 17, 19, 21]:\n",
    "    irony_train_roberta = cross_validation_ensemble_owa(irony_train_select, \n",
    "                    ['Vector_w2v_wt_stopwords'], 'sarcastic' K_fold, [k], additive(), additive())\n",
    "    p_irony, r_irony, f1_irony, support = \n",
    "        precision_recall_fscore_support(irony_train_roberta[\"sarcastic\"].to_list(), \n",
    "                            irony_train_roberta[\"Labels\"].to_list(), average = \"binary\", pos_label=1)\n",
    "    f1_list_wt_sw.append(f1_irony)\n",
    "    print(k, f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-1.2436440220376481, pvalue=0.2267200781180628)\n",
      "Ttest_indResult(statistic=-1.4258594434672731, pvalue=0.16794491080267582)\n",
      "Ttest_indResult(statistic=-2.447818599784717, pvalue=0.02281533955976826)\n"
     ]
    }
   ],
   "source": [
    "#if 0.05 > p-value - arrays are different\n",
    "\n",
    "print(ttest_ind(f1_list, f1_list_cleaned))\n",
    "print(ttest_ind(f1_list_cleaned, f1_list_wt_stopwords))\n",
    "print(ttest_ind(f1_list, f1_list_wt_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best embedding is for cleaned tweets without stopwords, for k = 5, F1 = 0.2050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best setups:\n",
    "    \n",
    "1. roBERTa: raw tweets, k = 5, F1 = 0.3722\n",
    "2. DeepMoji: cleaned tweets, k = 5, F1 = 0.3157 \n",
    "3. USE: raw tweets, k = 5, F1 = 0.2808\n",
    "4. BERT: cleaned tweets without stop-words, k = 5, F1 = 0.2351\n",
    "5. Word2Vec: cleaned tweets without stop-words, k = 5, F1 = 0.2050\n",
    "6. SBERT: raw tweets, k = 7, F1 = 0.1618 \\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score:  0.09956709956709958\n"
     ]
    }
   ],
   "source": [
    "irony_ensemble_labels = cross_validation_ensemble_owa(irony_train_select, ['Vector_roBERTa', \n",
    "                       'Vector_bert_wt_stopwords', 'Vector_sbert', 'Vector_use', \n",
    "                       'Vector_deepmoji_cleaned', 'Vector_w2v_wt_stopwords'], 'sarcastic', K_fold, \n",
    "                          [5, 5, 7, 5, 5, 5], additive(), additive())\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(\n",
    "    irony_ensemble_labels[\"sarcastic\"].to_list(), \n",
    "    [np.round(i) for i in irony_ensemble_labels[\"Labels\"].to_list()], average = \"binary\", pos_label=1)\n",
    "print(\"F1-score: \", f1_irony)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOP-5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score:  0.18664047151277016\n"
     ]
    }
   ],
   "source": [
    "irony_ensemble_labels = cross_validation_ensemble_owa(irony_train_select, ['Vector_roBERTa', \n",
    "                       'Vector_bert_wt_stopwords', 'Vector_w2v_wt_stopwords', 'Vector_use', \n",
    "                       'Vector_deepmoji_cleaned'], 'sarcastic', K_fold, [5, 5, 7, 5, 5], \n",
    "                          additive(), additive())\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(\n",
    "    irony_ensemble_labels[\"sarcastic\"].to_list(), \n",
    "    [np.round(i) for i in irony_ensemble_labels[\"Labels\"].to_list()], average = \"binary\", pos_label=1)\n",
    "print(\"F1-score: \", f1_irony)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOP-4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score:  0.13179916317991633\n"
     ]
    }
   ],
   "source": [
    "irony_ensemble_labels = cross_validation_ensemble_owa(irony_train_select, ['Vector_roBERTa', \n",
    "                       'Vector_bert_wt_stopwords', 'Vector_use', 'Vector_deepmoji_cleaned'], \n",
    "                      'sarcastic', K_fold, [5, 5, 5, 5], additive(), additive())\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(\n",
    "    irony_ensemble_labels[\"sarcastic\"].to_list(), \n",
    "    [np.round(i) for i in irony_ensemble_labels[\"Labels\"].to_list()], average = \"binary\", pos_label=1)\n",
    "print(\"F1-score: \", f1_irony)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOP-3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score:  0.29416884247171454\n"
     ]
    }
   ],
   "source": [
    "irony_ensemble_labels = cross_validation_ensemble_owa(irony_train_select, ['Vector_roBERTa', \n",
    "                       'Vector_use', 'Vector_deepmoji_cleaned'], 'sarcastic', K_fold, \n",
    "                          [5, 5, 5], additive(), additive())\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(\n",
    "    irony_ensemble_labels[\"sarcastic\"].to_list(), \n",
    "    [np.round(i) for i in irony_ensemble_labels[\"Labels\"].to_list()], average = \"binary\", pos_label=1)\n",
    "print(\"F1-score: \", f1_irony)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOP-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score:  0.18669314796425027\n"
     ]
    }
   ],
   "source": [
    "irony_ensemble_labels = cross_validation_ensemble_owa(irony_train_select, ['Vector_roBERTa', \n",
    "                   'Vector_deepmoji_cleaned'], 'sarcastic', K_fold, [5, 5], additive(), additive())\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(\n",
    "    irony_ensemble_labels[\"sarcastic\"].to_list(), \n",
    "    [np.round(i) for i in irony_ensemble_labels[\"Labels\"].to_list()], average = \"binary\", pos_label=1)\n",
    "print(\"F1-score: \", 0.18669314796425027)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembles are weaker than the single roBERTa model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best architecture:**\n",
    "\n",
    "For cross-validation F1-score = 0.3722\n",
    "\n",
    "- Embeddings: roBERTa\n",
    "- Preprocessing: no\n",
    "- k: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "\n",
    "irony_test = pd.read_csv('./data/taskA.En.input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Size on the the Toulouse team, That pack is mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pinball!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So the Scottish Government want people to get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>villainous pro tip : change the device name on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would date any of these men ü•∫</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Size on the the Toulouse team, That pack is mo...\n",
       "1                                           Pinball!\n",
       "2  So the Scottish Government want people to get ...\n",
       "3  villainous pro tip : change the device name on...\n",
       "4                    I would date any of these men ü•∫"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset \n",
    "\n",
    "irony_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply roBERTa model\n",
    "\n",
    "irony_test['Vector_roBERTa'] = irony_test['text'].apply(lambda x: \n",
    "                                                    get_vector_roberta(x, tokenizer_roberta, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predicted labels\n",
    "\n",
    "irony_test_labels = test_ensemble(irony_train_select, irony_train_select['sarcastic'], \n",
    "                                  irony_test, ['Vector_roBERTa'], [5], additive(), additive())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions in .txt format for the submition\n",
    "\n",
    "irony_test_labels_int = [int(i) for i in irony_test_labels]\n",
    "with open('labels.txt', 'w') as f:\n",
    "    for item in irony_test_labels_int:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After the competition ended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read predicted labels from file is needed \n",
    "\n",
    "with open('labels.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "lines = lines[1:]\n",
    "pred_labels = [int(i.replace('\\n', '')) for i in lines]\n",
    "pred_labels\n",
    "\n",
    "# Otherwise, rename variable:\n",
    "# pred_labels = irony_test_labels_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read labeled test data\n",
    "\n",
    "irony_test_labeled = pd.read_csv('./data/task_A_En_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Size on the the Toulouse team, That pack is mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sarcastic\n",
       "0  Size on the the Toulouse team, That pack is mo...          0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look on the labeled data\n",
    "\n",
    "irony_test_labeled.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save real labels as a list\n",
    "\n",
    "real_labels = irony_test_labeled['sarcastic'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score rounded labels:  0.6552349845763019\n"
     ]
    }
   ],
   "source": [
    "# Calculate marco F1-score\n",
    "\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(real_labels, pred_labels, average = \"macro\")\n",
    "print(\"F1-score rounded labels: \", f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score rounded labels:  0.4242424242424242\n"
     ]
    }
   ],
   "source": [
    "# Calculate sarcastic F1-score - our score from leader-board\n",
    "\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(real_labels, pred_labels, average = \"binary\", pos_label=1)\n",
    "print(\"F1-score rounded labels: \", f1_irony)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check neigbours of test tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect wrong predictions\n",
    "\n",
    "error_ind = [i for i in range(len(real_labels)) if real_labels[i] != pred_labels[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of the CORRECT prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So the Scottish Government want people to get their booster shots so badly that the website doesn't even work\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Test instance to examine \n",
    "\n",
    "i = 2\n",
    "print(irony_test_labeled['text'].iloc[i])\n",
    "print(irony_test_labeled['sarcastic'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['I\\'d like to thank middle aged men watching the Olympics for solving the mental health crisis. Getting someone to shout \"get some perspective\" at every athlete struggling with anxiety will definitely solve their problem.',\n",
       "  'I love health insurance so much fun paying $100‚Äôs a month and then $100‚Äôs for basic medical services that somehow aren‚Äôt covered. #America',\n",
       "  'YouTube just gave me a gamer targeted covid vaccine ad and anyway get vaccinated gamers.',\n",
       "  'V excited to grant an extension to students who email me and my co-teacher and get both of our names wrong',\n",
       "  'We really need to remind people that universal healthcare means never needing to sit through another annual explanation of benefits meeting'],\n",
       " [1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find neighbouring train instances \n",
    "\n",
    "test_vector = irony_test['Vector_roBERTa'].iloc[i]\n",
    "get_neigbours(test_vector, irony_train_select, 'Vector_roBERTa', 5, 'tweet', 'sarcastic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of the WRONG prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sometimes I lay in bed and think about how today will be the day I make my life better. Exercise, drinking water, eating healthy. Then I wake up. \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "i = error_ind[0]\n",
    "print(irony_test_labeled['text'].iloc[i])\n",
    "print(irony_test_labeled['sarcastic'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['me: I‚Äôm gonna wash my hair and shave my legs! \\r\\nMe instead: I‚Äôm gonna dissociate in the shower for 45 minutes',\n",
       "  \"I think I've figured out why Ted Cruz always looks like he's melting.  It's because of the flames constantly emanating from his pants. #TXSenateDebate #LyinTed #LoseCruz #PantsOnFire\",\n",
       "  'July 1st. Half way point of the year. Well I think we can all agree that 2020 has gone swimmingly so far. \\r\\nCan‚Äôt wait for part 2. \\r\\n#murderhornets',\n",
       "  \"@nypost Since going keto, I haven't had sunburn, and I haven't used sunscreen either.  Also, since losing weight, when all my obese friends are sweating their nuts off, I seem to have a high heat tolerance.  One of many surprising benefits of a low carb lifestyle.\",\n",
       "  'Well, my vaccinated therapist tested positive for Covid.  Hope she‚Äôs okay and hope my mental health hangs on for 10 extra days.'],\n",
       " [0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vector = irony_test['Vector_roBERTa'].iloc[i]\n",
    "\n",
    "get_neigbours(test_vector, irony_train_select, 'Vector_roBERTa', 5, 'tweet', 'sarcastic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the weighted kNN classification model instead of OWA-FRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the wkNN instead of OWA-FRNN in our best setup (roBERTa with k=5) with cross-validation \n",
    "\n",
    "irony_train_wknn = cross_validation_ensemble_wknn(irony_train_select, 'Vector_roBERTa', \n",
    "                                                  'sarcastic', 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6015477117692167"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate macro F1-score \n",
    "\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(\n",
    "    irony_train_wknn[\"Prediction\"].to_list(), irony_train_select[\"sarcastic\"].to_list(), \n",
    "    average = \"macro\")\n",
    "print(f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35698282300224055"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate sarcastic F1-score\n",
    "\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(\n",
    "    irony_train_wknn[\"Prediction\"].to_list(), irony_train_select[\"sarcastic\"].to_list(), \n",
    "    average = \"binary\", pos_label=1)\n",
    "print(f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the wkNN to test data instead of OWA-FRNN to our best setup - roBERTa with k=5\n",
    "\n",
    "pred_labels_wknn = irony_test['Vector_roBERTa'].apply(lambda x: \n",
    "                                          weighted_knn(irony_train_select, 'Vector_roBERTa', x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score rounded labels:  0.6635198814833494\n"
     ]
    }
   ],
   "source": [
    "# Calculate macro F1-score (we got 0.6552 for OWA-FRNN)\n",
    "\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(real_labels, \n",
    "                                                                  pred_labels_wknn, average = \"macro\")\n",
    "print(\"F1-score rounded labels: \", f1_irony) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score rounded labels:  0.42990654205607476\n"
     ]
    }
   ],
   "source": [
    "# Calculate sarcastic F1-score (we got 0.4242 for OWA-FRNN)\n",
    "\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(real_labels, \n",
    "                                                  pred_labels_wknn, average = \"binary\", pos_label=1)\n",
    "print(\"F1-score rounded labels: \", f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2790294627383016\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sarcastic F1-score with cross-validation for k=17\n",
    "\n",
    "irony_train_wknn = cross_validation_ensemble_wknn(irony_train_select, 'Vector_roBERTa', \n",
    "                                                  'sarcastic', 5, 17)\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(\n",
    "    irony_train_wknn[\"Prediction\"].to_list(), irony_train_select[\"sarcastic\"].to_list(), \n",
    "    average = \"binary\", pos_label=1)\n",
    "print(f1_irony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49693251533742333\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sarcastic F1-score for test data with k=17\n",
    "\n",
    "pred_labels_wknn = irony_test['Vector_roBERTa'].apply(lambda x: \n",
    "                                          weighted_knn(irony_train_select, 'Vector_roBERTa', x, 17))\n",
    "p_irony, r_irony, f1_irony, support = precision_recall_fscore_support(real_labels, \n",
    "                                                  pred_labels_wknn, average = \"binary\", pos_label=1)\n",
    "print(f1_irony)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.data_preprocessing import *\n",
    "from code.tweets_embedding import *\n",
    "from code.frnn_owa_eval import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the embedding process, we applied some operations to clean the tweets.\n",
    "\n",
    "In the first, general step, we deleted account tags starting with ′@′, extra whitespaces, newline symbols (’\\n’), all numbers, and punctuation marks. We did not delete hashtags because they can be a source of useful information, so we just removed ′#′ symbols. Also, we replaced ’&’ with the word ’and’ and replaced emojis with their textual descriptions. \n",
    "\n",
    "The second step of tweet preprocessing is stop-word removal. \n",
    "\n",
    "Both general preprocessing and stop-word removal are optional for our purposes:  during  the  experimental  stage,  we  examined  how  they  improved classification results and detected the best set up for each embedding method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original data with tweets preprocessing and stop-words cleaning\n",
    "# Dataset like 'anger_data' is a concatenation of train 'anger_train' and development 'anger_dev' datasets\n",
    "\n",
    "anger_train, anger_dev, anger_data, anger_test = upload_datasets('../data/SemEval2018-Task1-all-data/English_EI-oc/training/EI-oc-En-anger-train.txt', '../data/SemEval2018-Task1-all-data/English_EI-oc/development/2018-EI-oc-En-anger-dev.txt', '../data/SemEval2018-Task1-all-data/English_EI-oc/test-gold/2018-EI-oc-En-anger-test-gold.txt')\n",
    "joy_train, joy_dev, joy_data, joy_test = upload_datasets('../data/SemEval2018-Task1-all-data/English_EI-oc/training/EI-oc-En-joy-train.txt', '../data/SemEval2018-Task1-all-data/English_EI-oc/development/2018-EI-oc-En-joy-dev.txt', '../data/SemEval2018-Task1-all-data/English_EI-oc/test-gold/2018-EI-oc-En-joy-test-gold.txt')\n",
    "sad_train, sad_dev, sad_data, sad_test = upload_datasets('../data/SemEval2018-Task1-all-data/English_EI-oc/training/EI-oc-En-sadness-train.txt', '../data/SemEval2018-Task1-all-data/English_EI-oc/development/2018-EI-oc-En-sadness-dev.txt', '../data/SemEval2018-Task1-all-data/English_EI-oc/test-gold/2018-EI-oc-En-sadness-test-gold.txt')\n",
    "fear_train, fear_dev, fear_data, fear_test = upload_datasets('../data/SemEval2018-Task1-all-data/English_EI-oc/training/EI-oc-En-fear-train.txt', '../data/SemEval2018-Task1-all-data/English_EI-oc/development/2018-EI-oc-En-fear-dev.txt', '../data/SemEval2018-Task1-all-data/English_EI-oc/test-gold/2018-EI-oc-En-fear-test-gold.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Cleaned_tweet</th>\n",
       "      <th>Cleaned_tweet_wt_stopwords</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-En-10264</td>\n",
       "      <td>@xandraaa5 @amayaallyn6 shut up hashtags are c...</td>\n",
       "      <td>shut up hashtags are cool offended</td>\n",
       "      <td>shut hashtags cool offended</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-En-10072</td>\n",
       "      <td>it makes me so fucking irate jesus. nobody is ...</td>\n",
       "      <td>it makes me so fucking irate jesus nobody is c...</td>\n",
       "      <td>makes fucking irate jesus nobody calling ppl l...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-En-11383</td>\n",
       "      <td>Lol Adam the Bull with his fake outrage...</td>\n",
       "      <td>lol adam the bull with his fake outrage</td>\n",
       "      <td>lol adam bull fake outrage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-En-11102</td>\n",
       "      <td>@THATSSHAWTYLO passed away early this morning ...</td>\n",
       "      <td>passed away early this morning in a fast and f...</td>\n",
       "      <td>passed away early morning fast furious styled ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-En-11506</td>\n",
       "      <td>@Kristiann1125 lol wow i was gonna say really?...</td>\n",
       "      <td>lol wow i was gonna say really haha have you s...</td>\n",
       "      <td>lol wow gonna say really haha seen chris nah d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  \\\n",
       "0  2017-En-10264  @xandraaa5 @amayaallyn6 shut up hashtags are c...   \n",
       "1  2017-En-10072  it makes me so fucking irate jesus. nobody is ...   \n",
       "2  2017-En-11383         Lol Adam the Bull with his fake outrage...   \n",
       "3  2017-En-11102  @THATSSHAWTYLO passed away early this morning ...   \n",
       "4  2017-En-11506  @Kristiann1125 lol wow i was gonna say really?...   \n",
       "\n",
       "                                       Cleaned_tweet  \\\n",
       "0                 shut up hashtags are cool offended   \n",
       "1  it makes me so fucking irate jesus nobody is c...   \n",
       "2            lol adam the bull with his fake outrage   \n",
       "3  passed away early this morning in a fast and f...   \n",
       "4  lol wow i was gonna say really haha have you s...   \n",
       "\n",
       "                          Cleaned_tweet_wt_stopwords  Class  \n",
       "0                        shut hashtags cool offended      2  \n",
       "1  makes fucking irate jesus nobody calling ppl l...      3  \n",
       "2                         lol adam bull fake outrage      1  \n",
       "3  passed away early morning fast furious styled ...      0  \n",
       "4  lol wow gonna say really haha seen chris nah d...      1  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of the dataset\n",
    "\n",
    "anger_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characteristics of  anger_data\n",
      "Number of instances:  2089\n",
      "Size of the smallest class:  376\n",
      "Imbalance Ratio (IR):  1.68\n",
      "\n",
      "\n",
      "Characteristics of  joy_data\n",
      "Number of instances:  1906\n",
      "Size of the smallest class:  410\n",
      "Imbalance Ratio (IR):  1.47\n",
      "\n",
      "\n",
      "Characteristics of  sad_data\n",
      "Number of instances:  1930\n",
      "Size of the smallest class:  348\n",
      "Imbalance Ratio (IR):  2.2\n",
      "\n",
      "\n",
      "Characteristics of  fear_data\n",
      "Number of instances:  2641\n",
      "Size of the smallest class:  217\n",
      "Imbalance Ratio (IR):  8.02\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Datasets charachteristics\n",
    "\n",
    "for dataset in [anger_data, joy_data, sad_data, fear_data]:\n",
    "    print('Characteristics of ', namestr(dataset, globals())[0])\n",
    "    print('Number of instances: ', len(dataset))\n",
    "    print('Size of the smallest class: ', min([len(dataset[dataset.Class == i]) for i in range(4)]))\n",
    "    print('Imbalance Ratio (IR): ', round(max([len(dataset[dataset.Class == i]) for i in range(4)])/min([len(dataset[dataset.Class == i]) for i in range(4)]), 2))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply embedding methods to calculate vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, we represent each tweet as a vector, to perform classification. For this purpose, we use the following six word- or sentence-level embedding techniques. \n",
    "\n",
    "For each embedding method we already defined the best tweet preprocessing technique: none ('Tweet'), the general cleaning ('Cleaned_tweet'), or the general cleaning with stop-words removing ('Cleaned_tweet_wt_stopwords')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepMoji\n",
    "# No preprocessing needed for all emotion datasets\n",
    "\n",
    "anger_data['Vector_deepmoji'] = get_vectors_deepmoji(anger_data, 'Tweet')\n",
    "anger_test['Vector_deepmoji'] = get_vectors_deepmoji(anger_test, 'Tweet')\n",
    "\n",
    "joy_data['Vector_deepmoji'] = get_vectors_deepmoji(joy_data, 'Tweet')\n",
    "joy_test['Vector_deepmoji'] = get_vectors_deepmoji(joy_test, 'Tweet')\n",
    "\n",
    "sad_data['Vector_deepmoji'] = get_vectors_deepmoji(sad_data, 'Tweet')\n",
    "sad_test['Vector_deepmoji'] = get_vectors_deepmoji(sad_test, 'Tweet')\n",
    "\n",
    "fear_data['Vector_deepmoji'] = get_vectors_deepmoji(fear_data, 'Tweet')\n",
    "fear_test['Vector_deepmoji'] = get_vectors_deepmoji(fear_test, 'Tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter-roBERTa-based\n",
    "# Tweets cleaning needed fo rall emotion datasets\n",
    "\n",
    "anger_data['Vector_roBERTa'] = anger_data['Cleaned_tweet'].apply(get_vector_roberta)\n",
    "anger_test['Vector_roBERTa'] = anger_test['Cleaned_tweet'].apply(get_vector_roberta)\n",
    "\n",
    "joy_data['Vector_roBERTa'] = joy_data['Cleaned_tweet'].apply(get_vector_roberta)\n",
    "joy_test['Vector_roBERTa'] = joy_test['Cleaned_tweet'].apply(get_vector_roberta)\n",
    "\n",
    "sad_data['Vector_roBERTa'] = sad_data['Cleaned_tweet'].apply(get_vector_roberta)\n",
    "sad_test['Vector_roBERTa'] = sad_test['Cleaned_tweet'].apply(get_vector_roberta)\n",
    "\n",
    "fear_data['Vector_roBERTa'] = fear_data['Cleaned_tweet'].apply(get_vector_roberta)\n",
    "fear_test['Vector_roBERTa'] = fear_test['Cleaned_tweet'].apply(get_vector_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "# With preprocessing and stop-words cleaning for all emotion datasets\n",
    "\n",
    "anger_data[\"Vector_w2v\"] = anger_data['Cleaned_tweet_wt_stopwords'].apply(lambda x: get_vector_w2v(x))\n",
    "anger_test[\"Vector_w2v\"] = anger_test['Cleaned_tweet_wt_stopwords'].apply(lambda x: get_vector_w2v(x))\n",
    "   \n",
    "joy_data[\"Vector_w2v\"] = joy_data['Cleaned_tweet_wt_stopwords'].apply(lambda x: get_vector_w2v(x))\n",
    "joy_test[\"Vector_w2v\"] = joy_test['Cleaned_tweet_wt_stopwords'].apply(lambda x: get_vector_w2v(x))\n",
    "\n",
    "sad_data[\"Vector_w2v\"] = sad_data['Cleaned_tweet_wt_stopwords'].apply(lambda x: get_vector_w2v(x))\n",
    "sad_test[\"Vector_w2v\"] = sad_test['Cleaned_tweet_wt_stopwords'].apply(lambda x: get_vector_w2v(x))\n",
    "\n",
    "fear_data[\"Vector_w2v\"] = fear_data['Cleaned_tweet_wt_stopwords'].apply(lambda x: get_vector_w2v(x))\n",
    "fear_test[\"Vector_w2v\"] = fear_test['Cleaned_tweet_wt_stopwords'].apply(lambda x: get_vector_w2v(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal Sentence Encoder \n",
    "# With preprocessing for all emotion datasets\n",
    "\n",
    "anger_data['Vector_use'] = anger_data['Cleaned_tweet'].apply(lambda x: get_vector_use(x))\n",
    "anger_test['Vector_use'] = anger_test['Cleaned_tweet'].apply(lambda x: get_vector_use(x))\n",
    "\n",
    "joy_data['Vector_use'] = joy_data['Cleaned_tweet'].apply(lambda x: get_vector_use(x))\n",
    "joy_test['Vector_use'] = joy_test['Cleaned_tweet'].apply(lambda x: get_vector_use(x))\n",
    "\n",
    "sad_data['Vector_use'] = sad_data['Cleaned_tweet'].apply(lambda x: get_vector_use(x))\n",
    "sad_test['Vector_use'] = sad_test['Cleaned_tweet'].apply(lambda x: get_vector_use(x))\n",
    "\n",
    "fear_data['Vector_use'] = fear_data['Cleaned_tweet'].apply(lambda x: get_vector_use(x))\n",
    "fear_test['Vector_use'] = fear_test['Cleaned_tweet'].apply(lambda x: get_vector_use(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence-BERT \n",
    "# With preprocessing for all emotion datasets\n",
    "\n",
    "anger_data['Vector_sbert'] = anger_data['Cleaned_tweet'].apply(get_vector_sbert)\n",
    "anger_test['Vector_sbert'] = anger_test['Cleaned_tweet'].apply(get_vector_sbert)\n",
    "\n",
    "joy_data['Vector_sbert'] = joy_data['Cleaned_tweet'].apply(get_vector_sbert)\n",
    "joy_test['Vector_sbert'] = joy_test['Cleaned_tweet'].apply(get_vector_sbert)\n",
    "\n",
    "sad_data['Vector_sbert'] = sad_data['Cleaned_tweet'].apply(get_vector_sbert)\n",
    "sad_test['Vector_sbert'] = sad_test['Cleaned_tweet'].apply(get_vector_sbert)\n",
    "\n",
    "fear_data['Vector_sbert'] = fear_data['Cleaned_tweet'].apply(get_vector_sbert)\n",
    "fear_test['Vector_sbert'] = fear_test['Cleaned_tweet'].apply(get_vector_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT \n",
    "# With raw tweets \n",
    "\n",
    "anger_data['Vector_bert'] = anger_data['Tweet'].apply(get_vector_bert)\n",
    "anger_test['Vector_bert'] = anger_test['Tweet'].apply(get_vector_bert)\n",
    "\n",
    "joy_data['Vector_bert'] = joy_data['Tweet'].apply(get_vector_bert)\n",
    "joy_test['Vector_bert'] = joy_test['Tweet'].apply(get_vector_bert)\n",
    "\n",
    "sad_data['Vector_bert'] = sad_data['Tweet'].apply(get_vector_bert)\n",
    "sad_test['Vector_bert'] = sad_test['Tweet'].apply(get_vector_bert)\n",
    "\n",
    "fear_data['Vector_bert'] = fear_data['Tweet'].apply(get_vector_bert)\n",
    "fear_test['Vector_bert'] = fear_test['Tweet'].apply(get_vector_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform cross-evaluation of different embedding methods with FRNN OWA classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the FRNN-OWA classifier for each embedding appraoch. In order to examine the influence of the obtained classification results, we will used different 'k' values for the best-performing approaches in our experiments for each dataset. The best obtained 'k' values for each combination dataset-embedding are used below. We also figured out, that the best results were obtained with the additive OWA type for upper and lower ap-proximations for most embeddings, so we chose them for the further experiments. \n",
    "\n",
    "Initially, we used only labels provided by FRNN-OWA classifiers, without confidence scores usage.\n",
    "\n",
    "We  used  5-fold  cross-validation  to  evaluate  the  results  of  our  approaches.  As evaluation measure, the Pearson Correlation Coefficient (PCC) was chosen, as it was also the evaluation measure used for the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of cross-validation folds\n",
    "K_fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger dataset with roBERTa-based embedding\n",
      "PCC:  0.6464873634462883\n",
      "Joy dataset with roBERTa-based embedding\n",
      "PCC:  0.6735542105170109\n",
      "Sadness dataset with roBERTa-based embedding\n",
      "PCC:  0.6611541153014013\n",
      "Fear dataset with roBERTa-based embedding\n",
      "PCC:  0.5888929793465107\n"
     ]
    }
   ],
   "source": [
    "# We use 'cross_validation_ensemble_owa' function with one vector and one corresponded k\n",
    "\n",
    "# roBERTa-based model\n",
    "print('Anger dataset with roBERTa-based embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(anger_data, ['Vector_roBERTa'], K_fold, [19], additive(), additive(), 'labels'))\n",
    "print('Joy dataset with roBERTa-based embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(joy_data, ['Vector_roBERTa'], K_fold, [9], additive(), additive(), 'labels'))\n",
    "print('Sadness dataset with roBERTa-based embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(sad_data, ['Vector_roBERTa'], K_fold, [23], additive(), additive(), 'labels'))\n",
    "print('Fear dataset with roBERTa-based embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(fear_data, ['Vector_roBERTa'], K_fold, [9], additive(), additive(), 'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger dataset with DeepMoji embedding\n",
      "PCC:  0.5438111296817684\n",
      "Joy dataset with DeepMoji embedding\n",
      "PCC:  0.6214244583495802\n",
      "Sadness dataset with DeepMoji embedding\n",
      "PCC:  0.576854211632575\n",
      "Fear dataset with DeepMoji embedding\n",
      "PCC:  0.5043689724239788\n"
     ]
    }
   ],
   "source": [
    "# DeepMoji model\n",
    "print('Anger dataset with DeepMoji embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(anger_data, ['Vector_deepmoji'], K_fold, [23], additive(), additive(), 'labels'))\n",
    "print('Joy dataset with DeepMoji embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(joy_data, ['Vector_deepmoji'], K_fold, [19], additive(), additive(), 'labels'))\n",
    "print('Sadness dataset with DeepMoji embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(sad_data, ['Vector_deepmoji'], K_fold, [23], additive(), additive(), 'labels'))\n",
    "print('Fear dataset with DeepMoji embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(fear_data, ['Vector_deepmoji'], K_fold, [21], additive(), additive(), 'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger dataset with BERT embedding\n",
      "PCC:  0.4456954766377472\n",
      "Joy dataset with BERT embedding\n",
      "PCC:  0.5065254334783876\n",
      "Sadness dataset with BERT embedding\n",
      "PCC:  0.4488626587861287\n",
      "Fear dataset with BERT embedding\n",
      "PCC:  0.45844506210205427\n"
     ]
    }
   ],
   "source": [
    "# BERT model\n",
    "print('Anger dataset with BERT embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(anger_data, ['Vector_bert'], K_fold, [19], additive(), additive(), 'labels'))\n",
    "print('Joy dataset with BERT embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(joy_data, ['Vector_bert'], K_fold, [17], additive(), additive(), 'labels'))\n",
    "print('Sadness dataset with BERT embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(sad_data, ['Vector_bert'], K_fold, [23], additive(), additive(), 'labels'))\n",
    "print('Fear dataset with BERT embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(fear_data, ['Vector_bert'], K_fold, [7], additive(), additive(), 'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger dataset with SBERT embedding\n",
      "PCC:  0.5008545771452125\n",
      "Joy dataset with SBERT embedding\n",
      "PCC:  0.5598644655143654\n",
      "Sadness dataset with SBERT embedding\n",
      "PCC:  0.5442157010834586\n",
      "Fear dataset with SBERT embedding\n",
      "PCC:  0.49480438073320665\n"
     ]
    }
   ],
   "source": [
    "# SBERT model \n",
    "print('Anger dataset with SBERT embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(anger_data, ['Vector_sbert'], K_fold, [19], additive(), additive(), 'labels'))\n",
    "print('Joy dataset with SBERT embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(joy_data, ['Vector_sbert'], K_fold, [15], additive(), additive(), 'labels'))\n",
    "print('Sadness dataset with SBERT embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(sad_data, ['Vector_sbert'], K_fold, [23], additive(), additive(), 'labels'))\n",
    "print('Fear dataset with SBERT embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(fear_data, ['Vector_sbert'], K_fold, [11], additive(), additive(), 'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger dataset with USE embedding\n",
      "PCC:  0.5042334104402324\n",
      "Joy dataset with USE embedding\n",
      "PCC:  0.5513573121589473\n",
      "Sadness dataset with USE embedding\n",
      "PCC:  0.5865315296525251\n",
      "Fear dataset with USE embedding\n",
      "PCC:  0.5441177544624183\n"
     ]
    }
   ],
   "source": [
    "# USE model \n",
    "print('Anger dataset with USE embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(anger_data, ['Vector_use'], K_fold, [23], additive(), additive(), 'labels'))\n",
    "print('Joy dataset with USE embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(joy_data, ['Vector_use'], K_fold, [23], additive(), additive(), 'labels'))\n",
    "print('Sadness dataset with USE embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(sad_data, ['Vector_use'], K_fold, [23], additive(), additive(), 'labels'))\n",
    "print('Fear dataset with USE embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(fear_data, ['Vector_use'], K_fold, [21], additive(), additive(), 'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger dataset with Word2Vec embedding\n",
      "PCC:  0.4846692630756858\n",
      "Joy dataset with Word2Vec embedding\n",
      "PCC:  0.5161972827682905\n",
      "Sadness dataset with Word2Vec embedding\n",
      "PCC:  0.47221836156489855\n",
      "Fear dataset with Word2Vec embedding\n",
      "PCC:  0.4311917784564037\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec model \n",
    "print('Anger dataset with Word2Vec embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(anger_data, ['Vector_w2v'], K_fold, [21], additive(), additive(), 'labels'))\n",
    "print('Joy dataset with Word2Vec embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(joy_data, ['Vector_w2v'], K_fold, [23], additive(), additive(), 'labels'))\n",
    "print('Sadness dataset with Word2Vec embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(sad_data, ['Vector_w2v'], K_fold, [23], additive(), additive(), 'labels'))\n",
    "print('Fear dataset with Word2Vec embedding')\n",
    "print('PCC: ', cross_validation_ensemble_owa(fear_data, ['Vector_w2v'], K_fold, [7], additive(), additive(), 'labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation evaluation for ensemble of FRNN OWA models based on different embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the FRNN-OWA method both as a standalone method  and  as  part  of  a  classification  ensemble.  For  this  purpose,  a  separate model was trained for every choice of tweet embedding. Each model was based on each dataset’s best setup and embedding (choice of tweet preprocessing, OWA types, and the number of neighbours 'k'). \n",
    "\n",
    "To determine the test label, we use a weighted voting function on the different outputs of our models. The mean performed the best among other and was chosen as a primary voting function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting function - the mean of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach all models of ensemble have the same weights and FRNN-OWA methos returns the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6842759501834952"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anger dataset with all embeggings and k-s\n",
    "\n",
    "cross_validation_ensemble_owa(anger_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_sbert', 'Vector_use', 'Vector_w2v'], K_fold, [19, 23, 19, 19, 23, 21], additive(), additive(), 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7420823382643671"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joy dataset with all embeggings and k-s\n",
    "\n",
    "cross_validation_ensemble_owa(joy_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_sbert', 'Vector_use', 'Vector_w2v'], K_fold, [9, 19, 17, 15, 23, 23], additive(), additive(), 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7393055766899576"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sad dataset with all embeggings and k-s\n",
    "\n",
    "cross_validation_ensemble_owa(sad_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_sbert', 'Vector_use', 'Vector_w2v'], K_fold, [23, 23, 23, 23, 23, 23], additive(), additive(), 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6481174352923854"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fear dataset with all embeggings and k-s\n",
    "\n",
    "cross_validation_ensemble_owa(fear_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_sbert', 'Vector_use', 'Vector_w2v'], K_fold, [9, 21, 7, 11, 21, 7], additive(), additive(), 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting function - the mean of labels calculated with confidence scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach the FRNN-OWA clasiffier return the confidence scores of our labels, that are used to put different weightes on the models' outputs.\n",
    "\n",
    "A confidence score is a float value, usually between 0 and 1, provided by aclassification model for each prediction class. This value illustrates the accuracy of the model’s prediction for a particular class.\n",
    "\n",
    "In the end we figured out, that weighted average with confidence scores performed the best. It means that we upgrade the mean voting function with confidence scores as weights to calculate the prediction label as a weighted average of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6314359629929253"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anger dataset with all embeggings and k-s\n",
    "\n",
    "cross_validation_ensemble_owa(anger_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_sbert', 'Vector_use', 'Vector_w2v'], K_fold, [19, 23, 19, 19, 23, 21], additive(), additive(), 'conf_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6616195692551319"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joy dataset with all embeggings and k-s\n",
    "\n",
    "cross_validation_ensemble_owa(joy_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_sbert', 'Vector_use', 'Vector_w2v'], K_fold, [9, 19, 17, 15, 23, 23], additive(), additive(), 'conf_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6643773685191207"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sad dataset with all embeggings and k-s\n",
    "\n",
    "cross_validation_ensemble_owa(sad_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_sbert', 'Vector_use', 'Vector_w2v'], K_fold, [23, 23, 23, 23, 23, 23], additive(), additive(), 'conf_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5302812588261683"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fear dataset with all embeggings and k-s\n",
    "\n",
    "cross_validation_ensemble_owa(fear_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_sbert', 'Vector_use', 'Vector_w2v'], K_fold, [9, 21, 7, 11, 21, 7], additive(), additive(), 'conf_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best set up for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  last  step  of  ensemble  tuning  was  to  determine  the  most  accurate  set  of models in the ensemble. For this purpose, we used grid search, where the PCC score was calculated for each subset of all six models (features) and compared. The predicted label was calculated using a rounded average function with weights equal to the scaled confidence scores. \n",
    "\n",
    "In this way, we detected the best setup for each emotion dataset, that also contains the best 'k' value, the voting function and OWA types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6801480669739245"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For anger - confidence scores; features: roBERTa, DeepMoji, BERT, USE, Word2Vec; alpha = 0.0420\n",
    "\n",
    "cross_validation_ensemble_owa(anger_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_use', 'Vector_w2v'], K_fold, [19, 23, 19, 23, 21], additive(), additive(), 'conf_scores', 0.0420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7397918225616584"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For joy - confidence scores; features: roBERTa, DeepMoji, BERT, USE, SBERT; alpha = 0.0320\n",
    "\n",
    "cross_validation_ensemble_owa(joy_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_sbert', 'Vector_use'], K_fold, [9, 19, 17, 15, 23], additive(), additive(), 'conf_scores', 0.0320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7247581287413064"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For sadness - confidence scores; features: roBERTa, DeepMoji, USE, SBERT; alpha = 0.0320\n",
    "\n",
    "cross_validation_ensemble_owa(sad_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_sbert', 'Vector_use'], K_fold, [23, 23, 23, 23], additive(), additive(), 'conf_scores', 0.0320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6245784952669604"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For fear - confidence scores; features: roBERTa, DeepMoji, SBERT, USE, Word2Vec; alpha = 0.0460\n",
    "\n",
    "cross_validation_ensemble_owa(fear_data, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_sbert', 'Vector_use', 'Vector_w2v'], K_fold, [9, 21, 11, 21, 7], additive(), additive(), 'conf_scores', 0.0460)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data evaluation of the best approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the best ensemble’s effectiveness, we evaluate it on the test data. We calculate PCC values for each emotion dataset and average the results, as it was done by the competition organizers.\n",
    "\n",
    "As we can see, results for the test data are predictably worse than those for the combined training and development datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PCC score for anger data:  0.6432847625677238\n"
     ]
    }
   ],
   "source": [
    "# For anger\n",
    "\n",
    "anger_test_labels = test_ensemble_confscores(anger_data, anger_data['Class'], anger_test, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_use', 'Vector_w2v'], [19, 23, 19, 23, 21], additive(), additive(), 0.0420)\n",
    "anger_test_PCC = pearsonr(anger_test['Class'], anger_test_labels)[0]\n",
    "print(\"Test PCC score for anger data: \", anger_test_PCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PCC score for joy data:  0.6819870615829331\n"
     ]
    }
   ],
   "source": [
    "# For joy\n",
    "\n",
    "joy_test_labels = test_ensemble_confscores(joy_data, joy_data['Class'], joy_test, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_bert', 'Vector_sbert', 'Vector_use'], [9, 19, 17, 15, 23], additive(), additive(), 0.0320)\n",
    "joy_test_PCC = pearsonr(joy_test['Class'], joy_test_labels)[0]\n",
    "print(\"Test PCC score for joy data: \", joy_test_PCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PCC score for sad data:  0.6900805693475882\n"
     ]
    }
   ],
   "source": [
    "# For sadness\n",
    "\n",
    "sad_test_labels = test_ensemble_confscores(sad_data, sad_data['Class'], sad_test, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_sbert', 'Vector_use'], [23, 23, 23, 23], additive(), additive(), 0.0320)\n",
    "sad_test_PCC = pearsonr(sad_test['Class'], sad_test_labels)[0]\n",
    "print(\"Test PCC score for sad data: \", sad_test_PCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PCC score for fear data:  0.5759393410711254\n"
     ]
    }
   ],
   "source": [
    "# For fear\n",
    "\n",
    "fear_test_labels = test_ensemble_confscores(fear_data, fear_data['Class'], fear_test, ['Vector_roBERTa', 'Vector_deepmoji', 'Vector_sbert', 'Vector_use', 'Vector_w2v'], [9, 21, 11, 21, 7], additive(), additive(), 0.0460)\n",
    "fear_test_PCC = pearsonr(fear_test['Class'], fear_test_labels)[0]\n",
    "print(\"Test PCC score for fear data: \", fear_test_PCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average PCC value for 4 datasets:  0.6478229336423427\n"
     ]
    }
   ],
   "source": [
    "# The average PCC value\n",
    "\n",
    "print(\"The average PCC value for 4 datasets: \", (anger_test_PCC+joy_test_PCC+sad_test_PCC+fear_test_PCC)/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We submitted the predicted labels for the test data in the required format to the competition web page - https://competitions.codalab.org/competitions/17751#learn_the_details-evaluation. \n",
    "\n",
    "After submission, we took **the second place** in the competition leader board with **PCC = 0.654**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
